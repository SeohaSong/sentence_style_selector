{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Fetch argument None has invalid type <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ac89a6fec18f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1120\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    425\u001b[0m     \"\"\"\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m       raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n\u001b[1;32m--> 242\u001b[1;33m                                                                  type(fetch)))\n\u001b[0m\u001b[0;32m    243\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m       \u001b[1;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Fetch argument None has invalid type <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "a = tf.Variable(tf.truncated_normal([1]))\n",
    "b = tf.Variable(tf.truncated_normal([1]))\n",
    "loss = tf.losses.mean_squared_error(a, b)\n",
    "learn = tf.train.AdamOptimizer().minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./board', graph)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "summary = sess.run(merged, feed_dict={X: 1})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_summary(summary, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "add = tf.add(X, Y)\n",
    "\n",
    "writer = tf.summary.FileWriter('./board', sess.graph)\n",
    "writer.add_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뱔 비평계 현원 다이엘 사묘 에미 월야 마셜 튀니지 산인 잡류 리베리 창동 배런 깍지 바히나지오칸테 한명호 내취 만드셔 법무법인 식수대 미겔 엘더스 안소영 홍희관 아세이 아세이 신주쿠교엔 현대산업개발 혐녀 문무왕 나무판자 좌완 북해도 읕것 가루다 하빌랜드 김경민 뛰어다님 디선 됴앙 보도비첸코브 땁시다 절러 시종 김수임 강원 마고리 이열 반만년 첟 금지옥엽 괜차늠 똭똭 왈왈왈 쫑쫑 산세바스티안 감성돔 혐녀 꾸뻑 저기 김승호 비요른 장자크\n",
      "부르디외 쓰러져버렸 사진학 카밀 옴니아 줜나 장하 신춘문예 당했을까 빠구리 배리무어 쳉 엄영 몽사 껄떡 미복 게스리 허종호 강경론 미뉴엣 윤수일 시펑 김두봉 이혜리 부르디외 벌게져 히로타 항저우 괴로워진다 탤론 아마미 봣엇어요 뺴기냐 오발 전대 진이가 콘찰로프스키 콘도 바뀐다는데 벌 제께 법무법인 동호대교 양민영 퇴계 방성대곡 잔학성 태류 안재훈 마스다 똘똘한 도언 돕슨 주먹구구 배선 키시다 불가형언 산세바스티안 국봉 천연가스 괜츈한듯 살로 장하 각지\n",
      "김홍 츈 오동통 디브이 애재라 몽사 서태 이뤄지긴 디파이 씡난다아 급경사 월야 뽀옹 이뤄지긴 움킬 크레치만 벌라 서태 리버럴 입이 획일주의 획일주의 서상구 광장 원기 쿄오 간복 로렐라이 컴비네이션 백창우 쁑쁑류 정찰대 재은 능교 내당 걸 게스리 비바체 김두환 반음정 호우 안옥 팰런 윤무 쁑쁑류 누런색 뱅크헤드 승방 카약 하나무라 헣헣 끅 정채봉 제호 몽사 감김 무한리필 개기름 다포 백건 큽니당 접어 정진 고상지\n",
      "라펠 난바 전동현 보도비첸코브 저격술 락앤락 콕 차야 마카취일 총관 띳이즈쓰빠르따 정몽 인조반정 산세바스티안 합니데이 저격술 장록 원당 갸냘프 산화 괜츈한듯 복백 김윤호 양민영 몸져 공학윤리 달라진다 알베스 견족 권미경 문사 김승호 자치 박종환 후아나 혼연 색스 능해 소격동 서태 창동 스패니시 유중원 날카로워져 쑝카 친서 장하 달일 똠양꿍 김지훈 지취 김성현 이곤 설화지 정진 띳이즈쓰빠르따 쌓인다 라펠 천신만고 품명 헛헛헛 딕켄스 한지혜 정재희\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_sess():\n",
    "    tf.reset_default_graph()\n",
    "    graph = tf.get_default_graph()\n",
    "    lt = tf.constant(\n",
    "        pd.read_pickle('./data/lookup_table'),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    sen = tf.truncated_normal([4, 64, 512])\n",
    "    batch = tf.map_fn(lambda word: tf.map_fn(\n",
    "        lambda x: tf.cast(tf.argmin(\n",
    "            tf.norm((lt-x), axis=1)\n",
    "        ), dtype=tf.float32), word\n",
    "    ), sen)\n",
    "    sess = tf.Session()\n",
    "    return batch, sess, graph\n",
    "\n",
    "\n",
    "def batch2sens(batch):\n",
    "    \n",
    "    i2w = Word2Vec.load('./data/w2v_model').wv.index2word\n",
    "    \n",
    "    def get_sen(l):\n",
    "        ws = [\"<BLANK>\" if i == len(i2w) else i2w[i] for i in l]\n",
    "        sen = ' '.join(w.split('-')[0] for w in ws)\n",
    "        return sen\n",
    "\n",
    "    batch = batch.astype(int)\n",
    "    sens = [get_sen(l) for l in batch]\n",
    "    for sen in sens:\n",
    "        print(sen)\n",
    "\n",
    "\n",
    "batch, sess, graph = get_sess()\n",
    "batch_ = sess.run(batch)\n",
    "batch2sens(batch_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
