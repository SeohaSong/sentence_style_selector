{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from main import SSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = SSS()\n",
    "sss.set_hyper_parameters(256)\n",
    "sss.init_graph()\n",
    "sss.init_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00% | acc-l 0.4726562 | acc-v 0.5000000 | acc-l-s 0.5273438 | acc-v-s 0.0000000 | loss-gen 3.6382053\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    sss.run_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sss.debug(777)\n",
    "for mode in ['wake', 'sleep']:\n",
    "    print(result[mode]['sentence'])\n",
    "    for i in range(3):\n",
    "        print(result[mode]['label'][i])\n",
    "    for i in range(3):\n",
    "        print(result[mode]['valid'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 포스태깅 백터 추가해서 돌리기\n",
    "- 몇퍼센트 손상시킬지 정해주고 로스펑션에 반영하는 것이 당연함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_sess():\n",
    "    tf.reset_default_graph()\n",
    "    graph = tf.get_default_graph()\n",
    "    lt = tf.constant(\n",
    "        pd.read_pickle('./data/lookup_table'),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    sen = tf.truncated_normal([4, 64, 512])\n",
    "    batch = tf.map_fn(lambda word: tf.map_fn(\n",
    "        lambda x: tf.cast(tf.argmin(\n",
    "            tf.norm((lt-x), axis=1)\n",
    "        ), dtype=tf.float32), word\n",
    "    ), sen)\n",
    "    sess = tf.Session()\n",
    "    return batch, sess, graph\n",
    "\n",
    "\n",
    "def batch2sens(batch):\n",
    "    \n",
    "    i2w = Word2Vec.load('./data/w2v_model').wv.index2word\n",
    "    \n",
    "    def get_sen(l):\n",
    "        ws = [\"<BLANK>\" if i == len(i2w) else i2w[i] for i in l]\n",
    "        sen = ' '.join(w.split('-')[0] for w in ws)\n",
    "        return sen\n",
    "\n",
    "    batch = batch.astype(int)\n",
    "    sens = [get_sen(l) for l in batch]\n",
    "    for sen in sens:\n",
    "        print(sen)\n",
    "\n",
    "\n",
    "batch, sess, graph = get_sess()\n",
    "batch_ = sess.run(batch)\n",
    "batch2sens(batch_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
